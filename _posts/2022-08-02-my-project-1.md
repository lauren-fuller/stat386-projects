---
layout: post
title:  "Curating a Dataset by Web Scraping From Multiple Webpages"
date:   2022-10-20
author: Lauren Fuller
description: Learn how to currate a dataset by webscraping from multiple webpages using Beautifulsoup in python. 
image: /assets/images/WebScrape.jpg
---

## Overview

The internet contains an insane amount of data ready for analysis. To effectively obtain this data, we must learn how to web scrape. Web scraping is the process of extracting underlying HTML code of a website to replicate data or content from the website. I will walk you through an example below to show how I scrape movie data to build a dataset.

## Is it ethical to harvest data from public websites?

You are unlikely to have any problems if you're scraping a webpage in a respectful manner for educational purposes. However, it's still a good idea to make sure that you’re not violating any Terms of Service before staring. Just don't try to hide who you are and make sure not to do anything that will crash or slow a website. 

## The Data

I want to know if there are certain elements of a movie (ie. genre, runtime, release time, etc.) that are more likely than others to make a film successful (measured by ticket sales or gross profit). Therefore, the question to ask is: 
What elements of a movie nowadays make some films more successful than others?

We have a dataset (located [here](https://www.the-numbers.com/market/2022/top-grossing-movies)) of the movies so far released in the U.S and Cananda in 2022. This page contains a table with good starting info like genre, number of tickets sold, gross earnings, etc. However, we want to perform some good exploratory data analysis in the future on these movies to maybe predict what type of movie produced would be the most succesful. This will require some more data elements. Clicking the titles of the movies will take you to the indivdual pages of each movie. These individual pages provide you with more solid data for exploratory examination like running time and MPAA rating. We will scrape some data from the individual webpages for each movie as well as the table from the first webpage to currate a more well-rounded dataset. 


## Step 1: Inspect Your Data Source and Scrape the HTML code
First, you’ll want to get the site’s HTML code into your Python script so that you can interact with it. You can see the HTML script for a website by right-clicking and selecting "inspect". It should look something like this. This is the data we want to scrape.

<img src="https://i.postimg.cc/XN5143Pc/Screen-Shot-2022-10-19-at-7-10-24-PM.png)]" alt="drawing" width="650"/>

To begin the scraping process, install the requests library by running the following code in your computers terminal window:
<br />

`pip3 install requests`
<br />

Then run this code in your text editor: 
<br />

`import requests`
<br />

`from requests import get`

The next step is to use the requests library to issue an HTTP GET request to the given URL. This will retrieves the HTML data and store it in a Python object like so below.

<img src="https://i.postimg.cc/wTvV3pfG/Screen-Shot-2022-10-19-at-7-20-42-PM.png)]" alt="drawing" width="650"/>

If you print the .text attribute of `data`, you’ll see that it looks just like the HTML that you inspected earlier. You now have the website’s HTML within your Python script!

## Step 2: Parse the HTML code
The HTML text looks like a huge mess. To navigate through it, we will parse this lengthy code with the help of the Beautiful Soup library. 

To get started, install the Beautiful Soup library by running the following code in your computers terminal window:
<br />

`pip install beautifulsoup4`
<br />

Then, run this code in your text editor: 
<br />

`from bs4 import BeautifulSoup`

## Step 3: Find elements in HTML
In an HTML web page, you'll see a bunch of elements. The HTML element is everything from the start tag to the end tag. They look something like this:
<br />

`<h1>My First Heading</h1>`
<br />

`<p>My first paragraph.</p>`

For the movie data set specifically, we want to look for the `<table>` element and the tags within it since that is where the data we want to extract lies. Let's take a look at the `<table>` tag and the the tags nested within it to find the data .

<img src="https://i.postimg.cc/F1tVdf5c/Screen-Shot-2022-10-20-at-1-34-06-PM.png" alt="drawing" width="650"/>

We see that each movie is wrapped it's own `<tr>` tag. But within each `<tr>`, the title, release date, distributor, and genre lie within a `<td>` tag and then futher lie within either `<a>`, `<b>`, or both. We need to exract this info. I won't walk you through every variable I scrape, as it would be lengthy. However, I will show you a few examples starting with the movie title. 

## Step 4: Extract the desired text data from the parsed elements on the main page

The title for each movie is in a `<b>` tag. No other `<b>` tags exist in the code so let's create an object called `movie_tags` that will keep a list of all of the `<b>` tags in the HTML code by using `.find_all()`.

<img src="https://i.postimg.cc/k5yjv114/Screen-Shot-2022-10-20-at-11-33-44-PM.png" alt="drawing" width="650"/>

Within the `<b>` tag, the title of the movie is contained within a nested `<a>` tag. So to extract the title from the `<a>` tag, we will loop through each `<b>` tag in the `movie_tags` list and extract the title by using `tag.a.text`. We will then append the text to a list called `titles`. We have now successfully extracted the movie titles!

There are many different ways to parse through HTML code. You can even search by class and id attributes along with elements to search with more specificity like so:
<br />

`movie_profit = html_code.find_all( "td", class_ = "data")`
<br />

`main_page = html_code.find(id = "main")`

Check out this [website](https://stackabuse.com/guide-to-parsing-html-with-beautifulsoup-in-python/) for more detailed information on how to parse according to class, id, and other tag attributes. 

## Step 5: Webscrape more info from the individual movie pages.

We need some more substantial information about these movies than what the table on the main page provides. This will require us to visit the individual webpages of each movie, parse through the HTML code, and extract the data. So let's begin!

We first need a list of all of the 376 urls. The HTML code of the main table contains the urls of each movie, so we need to parse through the main page. The urls are in the same element as the movie title so we can use the same code but make a few adjustments. 

<img src="https://i.postimg.cc/ZR6k4YRs/Screen-Shot-2022-10-21-at-7-45-57-AM.png" alt="drawing" width="650"/>

Now that we have a list of the urls stored in `urls`, we need to parse and extract the data from each webpage. Let's extract the movie rating for each film. 

After inspecting the HTML code for a couple of films, we see below that the rating for the film is contained within a `<a>` tag with a specific `href`. However, each film has a different `href` so we wont be able to parse by `href`. We therefore run into a pickle since there isn't another attribute specific to this data to filter by. 

<img src="https://i.postimg.cc/MGnTTJ2J/Screen-Shot-2022-10-21-at-1-34-33-PM.png" alt="drawing" width="650"/>

I found that the easiest way to work around this was to find all `<a>` tags, convert them to strings, and then make a list of all the tags that contain the base url `/market/mpaa-rating/`. I execute this from the code below.

<img src="https://i.postimg.cc/DwYSTdpZ/Screen-Shot-2022-10-21-at-2-21-17-PM.png" alt="drawing" width="650"/>

We then get a list of tags that looks like this:

<img src="https://i.postimg.cc/7Pnm9pdk/Screen-Shot-2022-10-21-at-1-51-29-PM.png" alt="drawing" width="650"/>

We now need to extract the ratings from all of those strings. I do this by first searching for the index of `</a>` and the index of the first occurence of `>`. We then just extract the range of the string from the `>` index + 1 and the `</a>` index. If the element in the list contains no rating, we will just append `N/A` to the list of movie ratings.

<img src="https://i.postimg.cc/kMf9zMpM/Screen-Shot-2022-10-21-at-2-23-11-PM.png" alt="drawing" width="650"/>

## Step 6: combine all extracted data into a dataframe.

We have now succesfully extracted data not only from the main table on the first webpage, but from 376 other webpages by scraping the individual movie ratings. I went ahead and scraped all of the other info from the webpages that result in the data frame below using similar practice to the examples above. After scraping all of the data I wanted, I combined it into the data frame below.

<img src="https://i.postimg.cc/br3t2Xg0/Screen-Shot-2022-10-21-at-2-30-55-PM.png" alt="drawing" width="650"/>

## Conclusion

In this post, I showed how to use python's beautiful soup and requests library to collect movie data from multiple web pages. I am interested in discovering what elements of a movie nowadays make some films more successful than others. So, in my next post, I will show how exploratory data analysis of this data can help me understand if some movies do better than others for particular reasons. 

In the meantime, if you have any suggestions for improvement, questions about my methods, or questions that you would like to see answered with this data, please comment below!

Feel free to also check out the entirety of my code and data found here in a GitHub repo. You'll be able to see how I scraped the rest of the data contained in the data frame. 
