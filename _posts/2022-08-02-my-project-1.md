---
layout: post
title:  "Curating a Dataset by Web Scraping From Multiple Webpages"
date:   2022-10-20
author: Lauren Fuller
description: Learn how to currate a dataset by webscraping from multiple webpages using Beautifulsoup in python. 
image: /assets/images/WebScrape.jpg
---

## Overview

The internet contains an insane amount of data ready for analysis. To effectively obtain this data, we must learn how to web scrape. Web scraping is the process of extracting underlying HTML code of a website to replicate data or content from the website. I will walk you through an example below to show how I scrape movie data to build a dataset.

## Is it ethical to harvest data from public websites?

You are unlikely to have any problems if you're scraping a webpage in a respectful manner for educational purposes. However, it's still a good idea to make sure that you’re not violating any Terms of Service before staring. Just don't try to hide who you are and make sure not to do anything that will crash or slow a website. 

## The Data

I want to know if there are certain elements of a movie (ie. genre, runtime, release time, etc.) that are more likely than others to make a film successful (measured by ticket sales or gross profit). Therefore, the question to ask is: 
What elements of a movie nowadays make some films more successful than others?

We have a dataset (located [here](https://www.the-numbers.com/market/2022/top-grossing-movies)) of the movies so far released in the U.S and Cananda in 2022. This page contains a table with good starting info like genre, number of tickets sold, gross earnings, etc. However, we want to perform some good exploratory data analysis in the future on these movies to maybe predict what type of movie produced would be the most succesful. This will require some more data elements. Clicking the titles of the movies will take you to the indivdual pages of each movie. These individual pages provide you with more solid data for exploratory examination like running time and MPAA rating. We will scrape some data from the individual webpages for each movie in the table from the first webpage to currate a more well-rounded dataset. 


## Step 1: Inspect Your Data Source and Scrape the HTML code
First, you’ll want to get the site’s HTML code into your Python script so that you can interact with it. You can see the HTML script for a website by right-clicking and selecting "inspect". It should look something like this. This is the data we want to scrape.

<img src="https://i.postimg.cc/XN5143Pc/Screen-Shot-2022-10-19-at-7-10-24-PM.png)]" alt="drawing" width="650"/>

To begin the scraping process, install the requests library by running the following code in your computers terminal window:
<br />

`pip3 install requests`
<br />

Then run this code in your text editor: 
<br />

`import requests`
<br />

`from requests import get`

The next step is to use the requests library to issue an HTTP GET request to the given URL. This will retrieves the HTML data and store it in a Python object like so below.

<img src="https://i.postimg.cc/wTvV3pfG/Screen-Shot-2022-10-19-at-7-20-42-PM.png)]" alt="drawing" width="650"/>

If you print the .text attribute of `data`, you’ll see that it looks just like the HTML that you inspected earlier. You now have the website’s HTML within your Python script!

## Step 2: Parse the HTML code
The HTML text looks like a huge mess. To navigate through it, we will parse this lengthy code with the help of the Beautiful Soup library. 

To get started, install the Beautiful Soup library by running the following code in your computers terminal window:
<br />

`pip install beautifulsoup4`
<br />

Then, run this code in your text editor: 
<br />

`from bs4 import BeautifulSoup`

## Step 3: Find elements in HTML
In an HTML web page, every element can have an id attribute assigned. As the name already suggests, that id attribute makes the element uniquely identifiable on the page. You can begin to parse your page by selecting a specific element by its ID.

## Extract the desired text data from the parsed elements
